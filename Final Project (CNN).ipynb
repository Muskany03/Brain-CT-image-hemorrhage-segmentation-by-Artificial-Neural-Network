{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce92734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_000012eaf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_000039fa0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_00005679d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_00008ce3c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_0000950d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752798</th>\n",
       "      <td>ID_ffff82e46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752799</th>\n",
       "      <td>ID_ffff922b9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752800</th>\n",
       "      <td>ID_ffffb670a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752801</th>\n",
       "      <td>ID_ffffcbff8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752802</th>\n",
       "      <td>ID_fffff9393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752803 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Image  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0       ID_000012eaf    0         0                 0                 0   \n",
       "1       ID_000039fa0    0         0                 0                 0   \n",
       "2       ID_00005679d    0         0                 0                 0   \n",
       "3       ID_00008ce3c    0         0                 0                 0   \n",
       "4       ID_0000950d7    0         0                 0                 0   \n",
       "...              ...  ...       ...               ...               ...   \n",
       "752798  ID_ffff82e46    0         0                 0                 0   \n",
       "752799  ID_ffff922b9    1         0                 0                 1   \n",
       "752800  ID_ffffb670a    1         0                 0                 0   \n",
       "752801  ID_ffffcbff8    0         0                 0                 0   \n",
       "752802  ID_fffff9393    0         0                 0                 0   \n",
       "\n",
       "        subarachnoid  subdural  \n",
       "0                  0         0  \n",
       "1                  0         0  \n",
       "2                  0         0  \n",
       "3                  0         0  \n",
       "4                  0         0  \n",
       "...              ...       ...  \n",
       "752798             0         0  \n",
       "752799             0         0  \n",
       "752800             1         0  \n",
       "752801             0         0  \n",
       "752802             0         0  \n",
       "\n",
       "[752803 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "file_dir = r'C:/Users/sarah/Documents/Python Scripts/7243 Final Project/'   \n",
    "\n",
    "labels = pd.read_csv(file_dir + 'hemorrhage-labels.csv')\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9315a163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_000012eaf.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_000039fa0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_00005679d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_00008ce3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_0000950d7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752798</th>\n",
       "      <td>ID_ffff82e46.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752799</th>\n",
       "      <td>ID_ffff922b9.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752800</th>\n",
       "      <td>ID_ffffb670a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752801</th>\n",
       "      <td>ID_ffffcbff8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752802</th>\n",
       "      <td>ID_fffff9393.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752803 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Image  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0       ID_000012eaf.jpg    0         0                 0                 0   \n",
       "1       ID_000039fa0.jpg    0         0                 0                 0   \n",
       "2       ID_00005679d.jpg    0         0                 0                 0   \n",
       "3       ID_00008ce3c.jpg    0         0                 0                 0   \n",
       "4       ID_0000950d7.jpg    0         0                 0                 0   \n",
       "...                  ...  ...       ...               ...               ...   \n",
       "752798  ID_ffff82e46.jpg    0         0                 0                 0   \n",
       "752799  ID_ffff922b9.jpg    1         0                 0                 1   \n",
       "752800  ID_ffffb670a.jpg    1         0                 0                 0   \n",
       "752801  ID_ffffcbff8.jpg    0         0                 0                 0   \n",
       "752802  ID_fffff9393.jpg    0         0                 0                 0   \n",
       "\n",
       "        subarachnoid  subdural  category  \n",
       "0                  0         0         0  \n",
       "1                  0         0         0  \n",
       "2                  0         0         0  \n",
       "3                  0         0         0  \n",
       "4                  0         0         0  \n",
       "...              ...       ...       ...  \n",
       "752798             0         0         0  \n",
       "752799             0         0         3  \n",
       "752800             1         0         4  \n",
       "752801             0         0         0  \n",
       "752802             0         0         0  \n",
       "\n",
       "[752803 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In the conditions list, the in-line comment explains which categorical dummy variable that relates to the column.\n",
    "These are explained here as well: \n",
    "normal case = 0 (i.e. no hemorrhage)\n",
    "epidural = 1; intraparenchymal = 2; intraventricular = 3; subarachnoid = 4; subdural = 5; multiple = 6\n",
    "\"\"\"\n",
    "conditions = [\n",
    "    # the 'multiple' case (i.e. has a 1 in two or more columns, not including 'any' column)\n",
    "    # .gt(1) :=  test for greater than 1\n",
    "    labels[['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural']].sum(1).gt(1),   # 6\n",
    "    labels['epidural'] == 1,   # 1\n",
    "    labels['intraparenchymal'] == 1,   # 2\n",
    "    labels['intraventricular'] == 1,   # 3\n",
    "    labels['subarachnoid'] == 1,   #4\n",
    "    labels['subdural'] == 1,   #5\n",
    "]\n",
    "outputs = [6, 1, 2, 3, 4, 5]\n",
    "\n",
    "# np.nan characteristic sets the default case (i.e. the 'normal' or no hemorrhage case as NaN so we can remove easily)\n",
    "# this could be changed to a zero if necessary \n",
    "dummy = np.select(conditions, outputs, 0)\n",
    "dummy = pd.Series(dummy)\n",
    "dummy.name = \"category\"\n",
    "\n",
    "labels_cat = pd.concat([labels, dummy], axis=1)\n",
    "labels_cat['Image'] =  labels_cat['Image'] + '.jpg'\n",
    "\n",
    "display(labels_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92524795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "test = []\n",
    "imagedir = []\n",
    "imagename = []\n",
    "c = 0\n",
    "\n",
    "for filename in glob.iglob(file_dir + 'renders/**', recursive=True):\n",
    "    if os.path.isfile(filename):\n",
    "        test.append(filename)\n",
    "        dirname, basename = os.path.split(test[c])\n",
    "        imagedir.append(dirname)\n",
    "        imagename.append(basename)\n",
    "        c += 1 # filter dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781405b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_000edbf38.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_00178eb80.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_001bb2c00.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_0026de01c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_004966e2d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373279</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fff24b028.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373280</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fff49fa03.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373281</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fff4c8969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373282</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fff4dc2f1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373283</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fffb16e96.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373284 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_path             Image\n",
       "0       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_000edbf38.jpg\n",
       "1       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_00178eb80.jpg\n",
       "2       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_001bb2c00.jpg\n",
       "3       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_0026de01c.jpg\n",
       "4       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_004966e2d.jpg\n",
       "...                                                   ...               ...\n",
       "373279  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fff24b028.jpg\n",
       "373280  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fff49fa03.jpg\n",
       "373281  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fff4c8969.jpg\n",
       "373282  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fff4dc2f1.jpg\n",
       "373283  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fffb16e96.jpg\n",
       "\n",
       "[373284 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = pd.DataFrame([imagedir, imagename], index=['image_path', 'Image']).T.explode('Image')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc1c7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>Image</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_000012eaf.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_000039fa0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_00005679d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_00008ce3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_0000950d7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752798</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ID_ffff82e46.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752799</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_ffff922b9.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752800</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_ffffb670a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ID_ffffcbff8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752802</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ID_fffff9393.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752803 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_path             Image  \\\n",
       "0       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_000012eaf.jpg   \n",
       "1       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_000039fa0.jpg   \n",
       "2       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_00005679d.jpg   \n",
       "3       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_00008ce3c.jpg   \n",
       "4       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_0000950d7.jpg   \n",
       "...                                                   ...               ...   \n",
       "752798                                                NaN  ID_ffff82e46.jpg   \n",
       "752799  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_ffff922b9.jpg   \n",
       "752800  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_ffffb670a.jpg   \n",
       "752801                                                NaN  ID_ffffcbff8.jpg   \n",
       "752802                                                NaN  ID_fffff9393.jpg   \n",
       "\n",
       "        any  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "0         0         0                 0                 0             0   \n",
       "1         0         0                 0                 0             0   \n",
       "2         0         0                 0                 0             0   \n",
       "3         0         0                 0                 0             0   \n",
       "4         0         0                 0                 0             0   \n",
       "...     ...       ...               ...               ...           ...   \n",
       "752798    0         0                 0                 0             0   \n",
       "752799    1         0                 0                 1             0   \n",
       "752800    1         0                 0                 0             1   \n",
       "752801    0         0                 0                 0             0   \n",
       "752802    0         0                 0                 0             0   \n",
       "\n",
       "        subdural  category  \n",
       "0              0         0  \n",
       "1              0         0  \n",
       "2              0         0  \n",
       "3              0         0  \n",
       "4              0         0  \n",
       "...          ...       ...  \n",
       "752798         0         0  \n",
       "752799         0         3  \n",
       "752800         0         4  \n",
       "752801         0         0  \n",
       "752802         0         0  \n",
       "\n",
       "[752803 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#img_nodups = img.drop_duplicates()\n",
    "clabels_dups = pd.merge(img, labels_cat, on=[\"Image\"], how = \"right\")\n",
    "clabels_na = clabels_dups.drop_duplicates(subset = \"Image\")\n",
    "clabels_na.reset_index(drop = True, inplace = True)\n",
    "\n",
    "display(clabels_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0ddf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>Image</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_000012eaf.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_000039fa0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_00005679d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_00008ce3c.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_0000950d7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116076</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fffc60817.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116077</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fffd00949.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116078</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_fffe2edb8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116079</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_ffff922b9.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116080</th>\n",
       "      <td>C:/Users/sarah/Documents/Python Scripts/7243 F...</td>\n",
       "      <td>ID_ffffb670a.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116081 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_path             Image  \\\n",
       "0       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_000012eaf.jpg   \n",
       "1       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_000039fa0.jpg   \n",
       "2       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_00005679d.jpg   \n",
       "3       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_00008ce3c.jpg   \n",
       "4       C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_0000950d7.jpg   \n",
       "...                                                   ...               ...   \n",
       "116076  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fffc60817.jpg   \n",
       "116077  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fffd00949.jpg   \n",
       "116078  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_fffe2edb8.jpg   \n",
       "116079  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_ffff922b9.jpg   \n",
       "116080  C:/Users/sarah/Documents/Python Scripts/7243 F...  ID_ffffb670a.jpg   \n",
       "\n",
       "        any  epidural  intraparenchymal  intraventricular  subarachnoid  \\\n",
       "0         0         0                 0                 0             0   \n",
       "1         0         0                 0                 0             0   \n",
       "2         0         0                 0                 0             0   \n",
       "3         0         0                 0                 0             0   \n",
       "4         0         0                 0                 0             0   \n",
       "...     ...       ...               ...               ...           ...   \n",
       "116076    1         0                 1                 1             0   \n",
       "116077    1         0                 0                 0             1   \n",
       "116078    1         0                 1                 1             0   \n",
       "116079    1         0                 0                 1             0   \n",
       "116080    1         0                 0                 0             1   \n",
       "\n",
       "        subdural  category  \n",
       "0              0         0  \n",
       "1              0         0  \n",
       "2              0         0  \n",
       "3              0         0  \n",
       "4              0         0  \n",
       "...          ...       ...  \n",
       "116076         0         6  \n",
       "116077         0         4  \n",
       "116078         0         6  \n",
       "116079         0         3  \n",
       "116080         0         4  \n",
       "\n",
       "[116081 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clabels = clabels_na.dropna()\n",
    "clabels.reset_index(drop = True, inplace = True)\n",
    "display(clabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21810f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipping for now for memory purposes\n",
    "size = []\n",
    "\n",
    "# save the image path in its own dataframe then enumerate through the path list NOT the labels.\n",
    "# then index and reindex the labels\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "counter = 0\n",
    "\n",
    "for path, image in zip(clabels.image_path, clabels.Image):\n",
    "    #print(n)\n",
    "    if len(np.mean(matplotlib.image.imread(path + '/' + image),axis=2).reshape(-1)) == 262144:\n",
    "        m += 1\n",
    "    else:\n",
    "        size.append(m)\n",
    "        display(path, image)\n",
    "        print(m)\n",
    "        counter += 1\n",
    "        m += 1\n",
    "        continue\n",
    "    n += 1\n",
    "print(counter)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ddd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipping for now for memory purposes\n",
    "final = clabels.drop(size)\n",
    "final.reset_index(drop = True, inplace = True)\n",
    "display(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c3863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "ID_026f9b78b.jpg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "## Need seeding to select same sample each time\n",
    "random.seed(42)\n",
    "\n",
    "img_list = list(clabels.Image)\n",
    "cat_list= list(clabels.category)\n",
    "\n",
    "normal=[]\n",
    "epid=[]\n",
    "intrap =[]\n",
    "intrav=[]\n",
    "suba =[]\n",
    "subd =[]\n",
    "multi =[]\n",
    "\n",
    "for i in range(len(cat_list)):\n",
    "    if cat_list[i]==0:\n",
    "        normal.append(img_list[i])\n",
    "    elif cat_list[i]==1:\n",
    "        epid.append(img_list[i])\n",
    "    elif cat_list[i]==2:\n",
    "        intrap.append(img_list[i])\n",
    "    elif cat_list[i]==3:\n",
    "        intrav.append(img_list[i])\n",
    "    elif cat_list[i]==4:\n",
    "        suba.append(img_list[i])\n",
    "    elif cat_list[i]==5:\n",
    "        subd.append(img_list[i])\n",
    "    elif cat_list[i]==6:\n",
    "        multi.append(img_list[i])\n",
    "    \n",
    "    \n",
    "normal_sample=random.sample(normal, k = 500)\n",
    "epid_sample=random.sample(epid, k = 500)\n",
    "intrap_sample=random.sample(intrap, k = 500)\n",
    "intrav_sample=random.sample(intrav, k = 500)\n",
    "suba_sample=random.sample(suba, k = 500)\n",
    "subd_sample=random.sample(subd, k = 500)\n",
    "multi_sample=random.sample(multi, k = 500)\n",
    "\n",
    "img_sample= normal_sample + epid_sample + intrap_sample + intrav_sample + suba_sample + subd_sample+ multi_sample\n",
    "\n",
    "y=[]\n",
    "\n",
    "print(len(img_sample))\n",
    "print(img_sample[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3d8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "imgs = []\n",
    "img_names=[]\n",
    "c=0\n",
    "\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2b5083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3500\n",
      "3500\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    try:\n",
    "        dirname, basename = os.path.split(test[i])\n",
    "        if basename in img_names:\n",
    "            continue\n",
    "    except:\n",
    "        print(\"not a file\")\n",
    "        continue\n",
    "    if basename in img_sample:\n",
    "        try:\n",
    "            imgs.append(Image.open(os.path.join(test[i])))\n",
    "            print(len(imgs))\n",
    "            img_names.append(basename)\n",
    "        except:\n",
    "            print(basename, \"cannot be added\")\n",
    "    else:\n",
    "        continue\n",
    "            \n",
    "\n",
    "print(len(imgs))\n",
    "print(len(img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(imgs))\n",
    "print(len(img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbc546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "\n",
    "for basename in img_names:\n",
    "    if basename in normal_sample:\n",
    "        y.append(0)\n",
    "    elif basename in epid_sample:\n",
    "        y.append(1)\n",
    "    elif basename in intrap_sample:\n",
    "        y.append(2)\n",
    "    elif basename in intrav_sample:\n",
    "        y.append(3)\n",
    "    elif basename in suba_sample:\n",
    "        y.append(4)\n",
    "    elif basename in subd_sample:\n",
    "        y.append(5)\n",
    "    elif basename in multi_sample:\n",
    "        y.append(6)\n",
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87355a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 500\n",
      "1 500\n",
      "2 500\n",
      "3 500\n",
      "4 500\n",
      "5 500\n",
      "6 500\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,7):\n",
    "    print(i, y.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d544b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "print(imgs[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef15a158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#This converts each image from a jpg into an array\n",
    "\n",
    "from numpy import asarray\n",
    "import skimage\n",
    "from skimage import measure\n",
    "\n",
    "print(len(imgs))\n",
    "\n",
    "print(type(imgs[0]))\n",
    "\n",
    "downsample = 4\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    imgs[i]=np.asarray(imgs[i])\n",
    "    imgs[i] = imgs[i]/255\n",
    "    r = skimage.measure.block_reduce(imgs[i][:, :, 0],\n",
    "                                 (downsample, downsample),\n",
    "                                 np.mean)\n",
    "    g = skimage.measure.block_reduce(imgs[i][:, :, 1],\n",
    "                                 (downsample, downsample),\n",
    "                                 np.mean)\n",
    "    b = skimage.measure.block_reduce(imgs[i][:, :, 2],\n",
    "                                 (downsample, downsample),\n",
    "                                 np.mean)\n",
    "    imgs[i] = np.stack((r, g, b), axis=-1)\n",
    "\n",
    "print(type(imgs[0]))\n",
    "print(np.shape(imgs[0]))  #This is the right shape for a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d6415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(128, 128, 3)\n",
      "3129\n",
      "3499\n"
     ]
    }
   ],
   "source": [
    "print(type(imgs[0]))\n",
    "print(np.shape(imgs[0]))  #This is the right shape for a CNN\n",
    "imgs_final=[]\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    if np.shape(imgs[i])==(128,128,3):\n",
    "        imgs_final.append(imgs[i])\n",
    "    else:\n",
    "        print(i)\n",
    "        \n",
    "print(len(imgs_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5ff0325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499\n",
      "(2799, 128, 128, 3)\n",
      "(700, 128, 128, 3)\n",
      "(2799,)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "del(y[3129])\n",
    "\n",
    "print(len(y))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "imgs_train, imgs_test, y_train, y_test = train_test_split(imgs_final, \n",
    "                                                    np.asarray(y), test_size=0.2)\n",
    "\n",
    "imgs_train= np.array(imgs_train)\n",
    "imgs_test= np.array(imgs_test)\n",
    "\n",
    "print(imgs_train.shape)\n",
    "print(imgs_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9529f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2799, 128, 128, 3)\n",
      "(700, 128, 128, 3)\n",
      "(2799, 7)\n",
      "(700, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "y_train = utils.to_categorical(y_train,7)\n",
    "y_test = utils.to_categorical(y_test,7)\n",
    "\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_train /= 255\n",
    "imgs_test /= 255\n",
    "\n",
    "print(imgs_train.shape)\n",
    "print(imgs_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddbde046",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=20, # how many epochs to wait before stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e2f608c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                802880    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 861,831\n",
      "Trainable params: 861,511\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5),\n",
    "                 padding='valid',\n",
    "                 input_shape=(128, 128, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(units=490, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a6b36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.7717 - accuracy: 0.2715 - val_loss: 1538.7570 - val_accuracy: 0.1657\n",
      "Epoch 2/200\n",
      "88/88 [==============================] - 63s 715ms/step - loss: 1.4947 - accuracy: 0.3101 - val_loss: 2192.6353 - val_accuracy: 0.1657\n",
      "Epoch 3/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.4451 - accuracy: 0.3233 - val_loss: 2084.3635 - val_accuracy: 0.1657\n",
      "Epoch 4/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.4140 - accuracy: 0.3373 - val_loss: 2041.4495 - val_accuracy: 0.1657\n",
      "Epoch 5/200\n",
      "88/88 [==============================] - 68s 771ms/step - loss: 1.3695 - accuracy: 0.3558 - val_loss: 1705.7781 - val_accuracy: 0.1657\n",
      "Epoch 6/200\n",
      "88/88 [==============================] - 64s 724ms/step - loss: 1.3570 - accuracy: 0.3551 - val_loss: 1350.6198 - val_accuracy: 0.1657\n",
      "Epoch 7/200\n",
      "88/88 [==============================] - 65s 742ms/step - loss: 1.3397 - accuracy: 0.3687 - val_loss: 1170.4216 - val_accuracy: 0.1657\n",
      "Epoch 8/200\n",
      "88/88 [==============================] - 65s 735ms/step - loss: 1.3144 - accuracy: 0.3744 - val_loss: 656.6321 - val_accuracy: 0.1657\n",
      "Epoch 9/200\n",
      "88/88 [==============================] - 63s 718ms/step - loss: 1.3173 - accuracy: 0.3669 - val_loss: 238.5540 - val_accuracy: 0.1657\n",
      "Epoch 10/200\n",
      "88/88 [==============================] - 63s 719ms/step - loss: 1.3036 - accuracy: 0.3748 - val_loss: 92.6436 - val_accuracy: 0.1600\n",
      "Epoch 11/200\n",
      "88/88 [==============================] - 63s 712ms/step - loss: 1.2984 - accuracy: 0.3809 - val_loss: 1.9644 - val_accuracy: 0.3514\n",
      "Epoch 12/200\n",
      "88/88 [==============================] - 66s 746ms/step - loss: 1.2974 - accuracy: 0.3823 - val_loss: 8.0451 - val_accuracy: 0.1914\n",
      "Epoch 13/200\n",
      "88/88 [==============================] - 63s 721ms/step - loss: 1.2784 - accuracy: 0.3869 - val_loss: 2.3422 - val_accuracy: 0.2914\n",
      "Epoch 14/200\n",
      "88/88 [==============================] - 63s 718ms/step - loss: 1.2834 - accuracy: 0.3855 - val_loss: 1.4173 - val_accuracy: 0.4243\n",
      "Epoch 15/200\n",
      "88/88 [==============================] - 63s 718ms/step - loss: 1.2807 - accuracy: 0.3898 - val_loss: 1.3847 - val_accuracy: 0.4286\n",
      "Epoch 16/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.2745 - accuracy: 0.4012 - val_loss: 1.4120 - val_accuracy: 0.4300\n",
      "Epoch 17/200\n",
      "88/88 [==============================] - 63s 715ms/step - loss: 1.2783 - accuracy: 0.3998 - val_loss: 1.6069 - val_accuracy: 0.3600\n",
      "Epoch 18/200\n",
      "88/88 [==============================] - 64s 724ms/step - loss: 1.2695 - accuracy: 0.3916 - val_loss: 1.4162 - val_accuracy: 0.4057\n",
      "Epoch 19/200\n",
      "88/88 [==============================] - 63s 717ms/step - loss: 1.2674 - accuracy: 0.4030 - val_loss: 1.4850 - val_accuracy: 0.3729\n",
      "Epoch 20/200\n",
      "88/88 [==============================] - 63s 717ms/step - loss: 1.2718 - accuracy: 0.4012 - val_loss: 1.5068 - val_accuracy: 0.4114\n",
      "Epoch 21/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.2748 - accuracy: 0.3987 - val_loss: 1.6126 - val_accuracy: 0.3571\n",
      "Epoch 22/200\n",
      "88/88 [==============================] - 63s 721ms/step - loss: 1.2573 - accuracy: 0.4159 - val_loss: 1.3672 - val_accuracy: 0.4300\n",
      "Epoch 23/200\n",
      "88/88 [==============================] - 63s 713ms/step - loss: 1.2588 - accuracy: 0.4101 - val_loss: 1.3911 - val_accuracy: 0.4000\n",
      "Epoch 24/200\n",
      "88/88 [==============================] - 63s 720ms/step - loss: 1.2573 - accuracy: 0.4148 - val_loss: 1.5679 - val_accuracy: 0.3629\n",
      "Epoch 25/200\n",
      "88/88 [==============================] - 63s 713ms/step - loss: 1.2517 - accuracy: 0.4062 - val_loss: 1.4093 - val_accuracy: 0.4229\n",
      "Epoch 26/200\n",
      "88/88 [==============================] - 63s 712ms/step - loss: 1.2583 - accuracy: 0.4087 - val_loss: 1.5371 - val_accuracy: 0.3786\n",
      "Epoch 27/200\n",
      "88/88 [==============================] - 63s 712ms/step - loss: 1.2571 - accuracy: 0.4155 - val_loss: 1.5230 - val_accuracy: 0.3700\n",
      "Epoch 28/200\n",
      "88/88 [==============================] - 64s 724ms/step - loss: 1.2472 - accuracy: 0.4209 - val_loss: 1.3756 - val_accuracy: 0.4500\n",
      "Epoch 29/200\n",
      "88/88 [==============================] - 63s 720ms/step - loss: 1.2546 - accuracy: 0.4062 - val_loss: 1.3751 - val_accuracy: 0.4443\n",
      "Epoch 30/200\n",
      "88/88 [==============================] - 63s 718ms/step - loss: 1.2572 - accuracy: 0.4137 - val_loss: 1.3983 - val_accuracy: 0.3943\n",
      "Epoch 31/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.2441 - accuracy: 0.4159 - val_loss: 1.3733 - val_accuracy: 0.4243\n",
      "Epoch 32/200\n",
      "88/88 [==============================] - 63s 713ms/step - loss: 1.2523 - accuracy: 0.4087 - val_loss: 1.3888 - val_accuracy: 0.3929\n",
      "Epoch 33/200\n",
      "88/88 [==============================] - 63s 714ms/step - loss: 1.2546 - accuracy: 0.4194 - val_loss: 1.4625 - val_accuracy: 0.3843\n",
      "Epoch 34/200\n",
      "88/88 [==============================] - 63s 717ms/step - loss: 1.2443 - accuracy: 0.4130 - val_loss: 1.4013 - val_accuracy: 0.4100\n",
      "Epoch 35/200\n",
      "88/88 [==============================] - 63s 713ms/step - loss: 1.2487 - accuracy: 0.4137 - val_loss: 1.3751 - val_accuracy: 0.4343\n",
      "Epoch 36/200\n",
      "88/88 [==============================] - 64s 724ms/step - loss: 1.2416 - accuracy: 0.4148 - val_loss: 1.3852 - val_accuracy: 0.4500\n",
      "Epoch 37/200\n",
      "88/88 [==============================] - 63s 716ms/step - loss: 1.2500 - accuracy: 0.4241 - val_loss: 1.4679 - val_accuracy: 0.3886\n",
      "Epoch 38/200\n",
      "88/88 [==============================] - 63s 715ms/step - loss: 1.2354 - accuracy: 0.4291 - val_loss: 1.4314 - val_accuracy: 0.4029\n",
      "Epoch 39/200\n",
      "88/88 [==============================] - 64s 725ms/step - loss: 1.2413 - accuracy: 0.4219 - val_loss: 1.3572 - val_accuracy: 0.4457\n",
      "Epoch 40/200\n",
      "88/88 [==============================] - 64s 733ms/step - loss: 1.2487 - accuracy: 0.4234 - val_loss: 1.3617 - val_accuracy: 0.4457\n",
      "Epoch 41/200\n",
      "88/88 [==============================] - 63s 720ms/step - loss: 1.2292 - accuracy: 0.4412 - val_loss: 1.3532 - val_accuracy: 0.4286\n",
      "Epoch 42/200\n",
      "88/88 [==============================] - 58s 654ms/step - loss: 1.2286 - accuracy: 0.4362 - val_loss: 1.3483 - val_accuracy: 0.4400\n",
      "Epoch 43/200\n",
      "88/88 [==============================] - 51s 583ms/step - loss: 1.2386 - accuracy: 0.4291 - val_loss: 1.3732 - val_accuracy: 0.4300\n",
      "Epoch 44/200\n",
      "88/88 [==============================] - 51s 583ms/step - loss: 1.2290 - accuracy: 0.4391 - val_loss: 1.3814 - val_accuracy: 0.4314\n",
      "Epoch 45/200\n",
      "88/88 [==============================] - 53s 607ms/step - loss: 1.2298 - accuracy: 0.4330 - val_loss: 1.3484 - val_accuracy: 0.4429\n",
      "Epoch 46/200\n",
      "88/88 [==============================] - 52s 586ms/step - loss: 1.2310 - accuracy: 0.4341 - val_loss: 1.3520 - val_accuracy: 0.4386\n",
      "Epoch 47/200\n",
      "88/88 [==============================] - 52s 587ms/step - loss: 1.2265 - accuracy: 0.4284 - val_loss: 1.3450 - val_accuracy: 0.4471\n",
      "Epoch 48/200\n",
      "88/88 [==============================] - 51s 584ms/step - loss: 1.2423 - accuracy: 0.4302 - val_loss: 1.3579 - val_accuracy: 0.4557\n",
      "Epoch 49/200\n",
      "88/88 [==============================] - 52s 588ms/step - loss: 1.2293 - accuracy: 0.4302 - val_loss: 1.3468 - val_accuracy: 0.4557\n",
      "Epoch 50/200\n",
      "88/88 [==============================] - 52s 593ms/step - loss: 1.2266 - accuracy: 0.4359 - val_loss: 1.5633 - val_accuracy: 0.3900\n",
      "Epoch 51/200\n",
      "88/88 [==============================] - 56s 639ms/step - loss: 1.2272 - accuracy: 0.4280 - val_loss: 1.3663 - val_accuracy: 0.4329\n",
      "Epoch 52/200\n",
      "88/88 [==============================] - 59s 665ms/step - loss: 1.2239 - accuracy: 0.4294 - val_loss: 1.3587 - val_accuracy: 0.4529\n",
      "Epoch 53/200\n",
      "88/88 [==============================] - 57s 646ms/step - loss: 1.2276 - accuracy: 0.4455 - val_loss: 1.3542 - val_accuracy: 0.4471\n",
      "Epoch 54/200\n",
      "88/88 [==============================] - 54s 614ms/step - loss: 1.2215 - accuracy: 0.4452 - val_loss: 1.3764 - val_accuracy: 0.4643\n",
      "Epoch 55/200\n",
      "88/88 [==============================] - 53s 606ms/step - loss: 1.2128 - accuracy: 0.4469 - val_loss: 1.3595 - val_accuracy: 0.4343\n",
      "Epoch 56/200\n",
      "88/88 [==============================] - 54s 610ms/step - loss: 1.2226 - accuracy: 0.4416 - val_loss: 1.4208 - val_accuracy: 0.4157\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 53s 604ms/step - loss: 1.2209 - accuracy: 0.4416 - val_loss: 1.4737 - val_accuracy: 0.3971\n",
      "Epoch 58/200\n",
      "88/88 [==============================] - 53s 607ms/step - loss: 1.2258 - accuracy: 0.4319 - val_loss: 1.3652 - val_accuracy: 0.4571\n",
      "Epoch 59/200\n",
      "88/88 [==============================] - 56s 637ms/step - loss: 1.2128 - accuracy: 0.4577 - val_loss: 1.3540 - val_accuracy: 0.4443\n",
      "Epoch 60/200\n",
      "88/88 [==============================] - 53s 602ms/step - loss: 1.2152 - accuracy: 0.4437 - val_loss: 1.4232 - val_accuracy: 0.4000\n",
      "Epoch 61/200\n",
      "88/88 [==============================] - 55s 624ms/step - loss: 1.2128 - accuracy: 0.4534 - val_loss: 1.3757 - val_accuracy: 0.4571\n",
      "Epoch 62/200\n",
      "88/88 [==============================] - 52s 589ms/step - loss: 1.2178 - accuracy: 0.4334 - val_loss: 1.3621 - val_accuracy: 0.4529\n",
      "Epoch 63/200\n",
      "88/88 [==============================] - 52s 588ms/step - loss: 1.2191 - accuracy: 0.4452 - val_loss: 1.3728 - val_accuracy: 0.4271\n",
      "Epoch 64/200\n",
      "88/88 [==============================] - 51s 577ms/step - loss: 1.2014 - accuracy: 0.4477 - val_loss: 1.3541 - val_accuracy: 0.4343\n",
      "Epoch 65/200\n",
      "88/88 [==============================] - 51s 581ms/step - loss: 1.2090 - accuracy: 0.4573 - val_loss: 1.3603 - val_accuracy: 0.4414\n",
      "Epoch 66/200\n",
      "88/88 [==============================] - 52s 586ms/step - loss: 1.2066 - accuracy: 0.4594 - val_loss: 1.3519 - val_accuracy: 0.4686\n",
      "Epoch 67/200\n",
      "88/88 [==============================] - 51s 585ms/step - loss: 1.2182 - accuracy: 0.4491 - val_loss: 1.3468 - val_accuracy: 0.4500\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "history = model.fit(imgs_train, \n",
    "                    y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(imgs_test, y_test), callbacks=early_stopping_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a93c7",
   "metadata": {},
   "source": [
    "Let's see if we get any better results by taking out the multi-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0063ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "ID_026f9b78b.jpg\n"
     ]
    }
   ],
   "source": [
    "# Trying again with a larger dataset\n",
    "\n",
    "import random\n",
    "## Need seeding to select same sample each time\n",
    "random.seed(42)\n",
    "\n",
    "img_list = list(clabels.Image)\n",
    "cat_list= list(clabels.category)\n",
    "\n",
    "normal=[]\n",
    "epid=[]\n",
    "intrap =[]\n",
    "intrav=[]\n",
    "suba =[]\n",
    "subd =[]\n",
    "multi =[]\n",
    "\n",
    "for i in range(len(cat_list)):\n",
    "    if cat_list[i]==0:\n",
    "        normal.append(img_list[i])\n",
    "    elif cat_list[i]==1:\n",
    "        epid.append(img_list[i])\n",
    "    elif cat_list[i]==2:\n",
    "        intrap.append(img_list[i])\n",
    "    elif cat_list[i]==3:\n",
    "        intrav.append(img_list[i])\n",
    "    elif cat_list[i]==4:\n",
    "        suba.append(img_list[i])\n",
    "    elif cat_list[i]==5:\n",
    "        subd.append(img_list[i])\n",
    "    elif cat_list[i]==6:\n",
    "        multi.append(img_list[i])\n",
    "    \n",
    "    \n",
    "normal_sample=random.sample(normal, k = 1000)\n",
    "epid_sample=random.sample(epid, k = 1000)\n",
    "intrap_sample=random.sample(intrap, k = 1200)\n",
    "intrav_sample=random.sample(intrav, k = 1200)\n",
    "suba_sample=random.sample(suba, k = 1200)\n",
    "subd_sample=random.sample(subd, k = 1200)\n",
    "multi_sample=random.sample(multi, k = 1200)\n",
    "\n",
    "img_sample= normal_sample + epid_sample + intrap_sample + intrav_sample + suba_sample + subd_sample + multi_sample\n",
    "\n",
    "y=[]\n",
    "\n",
    "print(len(img_sample))\n",
    "print(img_sample[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95056ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "imgs = []\n",
    "img_names=[]\n",
    "c=0\n",
    "\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "feb75143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    try:\n",
    "        dirname, basename = os.path.split(test[i])\n",
    "        if basename in img_names:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    if basename in img_sample:\n",
    "        try:\n",
    "            imgs.append(Image.open(os.path.join(test[i])))\n",
    "            img_names.append(basename)\n",
    "        except:\n",
    "            print(basename + \"cannnot be added\")\n",
    "    else:\n",
    "        continue\n",
    "            \n",
    "\n",
    "print(len(imgs))\n",
    "print(len(img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5815a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "\n",
    "for basename in img_names:\n",
    "    if basename in normal_sample:\n",
    "        y.append(0)\n",
    "    elif basename in epid_sample:\n",
    "        y.append(1)\n",
    "    elif basename in intrap_sample:\n",
    "        y.append(2)\n",
    "    elif basename in intrav_sample:\n",
    "        y.append(3)\n",
    "    elif basename in suba_sample:\n",
    "        y.append(4)\n",
    "    elif basename in subd_sample:\n",
    "        y.append(5)\n",
    "    elif basename in multi_sample:\n",
    "        y.append(6)\n",
    "\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a769f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "import skimage\n",
    "from skimage import measure\n",
    "\n",
    "print(len(imgs))\n",
    "\n",
    "print(type(imgs[0]))\n",
    "\n",
    "downsample = 4\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    imgs[i]=np.asarray(imgs[i])\n",
    "    imgs[i] = imgs[i]/255\n",
    "    r = skimage.measure.block_reduce(imgs[i][:, :, 0],\n",
    "                                 (downsample, downsample),\n",
    "                                 np.mean)\n",
    "    g = skimage.measure.block_reduce(imgs[i][:, :, 1],\n",
    "                                 (downsample, downsample),\n",
    "                                 np.mean)\n",
    "    b = skimage.measure.block_reduce(imgs[i][:, :, 2],\n",
    "                                 (downsample, downsample),\n",
    "                                 np.mean)\n",
    "    imgs[i] = np.stack((r, g, b), axis=-1)\n",
    "\n",
    "print(type(imgs[0]))\n",
    "print(np.shape(imgs[0]))  #This is the right shape for a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c39925d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(128, 128, 3)\n",
      "7997\n"
     ]
    }
   ],
   "source": [
    "print(type(imgs[0]))\n",
    "print(np.shape(imgs[0]))  #This is the right shape for a CNN\n",
    "imgs_final=[]\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    if np.shape(imgs[i])==(128,128,3):\n",
    "        imgs_final.append(imgs[i])\n",
    "    else:\n",
    "        del(y[i])\n",
    "        \n",
    "print(len(imgs_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54bcf419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6397, 128, 128, 3)\n",
      "(1600, 128, 128, 3)\n",
      "(6397,)\n",
      "(1600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "imgs_train, imgs_test, y_train, y_test = train_test_split(imgs_final, \n",
    "                                                    np.asarray(y), test_size=0.2)\n",
    "\n",
    "imgs_train= np.array(imgs_train)\n",
    "imgs_test= np.array(imgs_test)\n",
    "\n",
    "print(imgs_train.shape)\n",
    "print(imgs_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fd73954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6397, 128, 128, 3)\n",
      "(1600, 128, 128, 3)\n",
      "(6397, 7)\n",
      "(1600, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "\n",
    "y_train = utils.to_categorical(y_train,7)\n",
    "y_test = utils.to_categorical(y_test,7)\n",
    "\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_train /= 255\n",
    "imgs_test /= 255\n",
    "\n",
    "print(imgs_train.shape)\n",
    "print(imgs_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "37f360b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad7634ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,655\n",
      "Trainable params: 243,207\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5),\n",
    "                 padding='valid',\n",
    "                 input_shape=(128, 128, 3),\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(units=490, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9, decay=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "683eb1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "175/175 [==============================] - 105s 600ms/step - loss: 1.4079 - accuracy: 0.3569 - val_loss: 356.0670 - val_accuracy: 0.1364\n",
      "Epoch 2/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.3075 - accuracy: 0.3876 - val_loss: 338.9831 - val_accuracy: 0.1364\n",
      "Epoch 3/100\n",
      "175/175 [==============================] - 107s 609ms/step - loss: 1.2654 - accuracy: 0.4153 - val_loss: 237.2032 - val_accuracy: 0.1364\n",
      "Epoch 4/100\n",
      "175/175 [==============================] - 115s 659ms/step - loss: 1.2511 - accuracy: 0.4305 - val_loss: 104.8721 - val_accuracy: 0.1364\n",
      "Epoch 5/100\n",
      "175/175 [==============================] - 109s 624ms/step - loss: 1.2381 - accuracy: 0.4425 - val_loss: 8.8883 - val_accuracy: 0.1657\n",
      "Epoch 6/100\n",
      "175/175 [==============================] - 112s 637ms/step - loss: 1.2178 - accuracy: 0.4503 - val_loss: 11.3031 - val_accuracy: 0.1679\n",
      "Epoch 7/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.2126 - accuracy: 0.4623 - val_loss: 2.6022 - val_accuracy: 0.1936\n",
      "Epoch 8/100\n",
      "175/175 [==============================] - 108s 620ms/step - loss: 1.2009 - accuracy: 0.4627 - val_loss: 1.2948 - val_accuracy: 0.4436\n",
      "Epoch 9/100\n",
      "175/175 [==============================] - 114s 650ms/step - loss: 1.2034 - accuracy: 0.4632 - val_loss: 1.9148 - val_accuracy: 0.2836\n",
      "Epoch 10/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1938 - accuracy: 0.4614 - val_loss: 1.3787 - val_accuracy: 0.4229\n",
      "Epoch 11/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1947 - accuracy: 0.4587 - val_loss: 1.2876 - val_accuracy: 0.4350\n",
      "Epoch 12/100\n",
      "175/175 [==============================] - 109s 620ms/step - loss: 1.1834 - accuracy: 0.4736 - val_loss: 1.4607 - val_accuracy: 0.3836\n",
      "Epoch 13/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1777 - accuracy: 0.4711 - val_loss: 1.3015 - val_accuracy: 0.4343\n",
      "Epoch 14/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1797 - accuracy: 0.4648 - val_loss: 2.9296 - val_accuracy: 0.2700\n",
      "Epoch 15/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1803 - accuracy: 0.4739 - val_loss: 1.4021 - val_accuracy: 0.4007\n",
      "Epoch 16/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1758 - accuracy: 0.4837 - val_loss: 1.2823 - val_accuracy: 0.4379\n",
      "Epoch 17/100\n",
      "175/175 [==============================] - 112s 641ms/step - loss: 1.1795 - accuracy: 0.4736 - val_loss: 1.4554 - val_accuracy: 0.3943\n",
      "Epoch 18/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1663 - accuracy: 0.4791 - val_loss: 1.3004 - val_accuracy: 0.4264\n",
      "Epoch 19/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1640 - accuracy: 0.4795 - val_loss: 1.3485 - val_accuracy: 0.4150\n",
      "Epoch 20/100\n",
      "175/175 [==============================] - 109s 625ms/step - loss: 1.1626 - accuracy: 0.4795 - val_loss: 1.3611 - val_accuracy: 0.4129\n",
      "Epoch 21/100\n",
      "175/175 [==============================] - 110s 626ms/step - loss: 1.1676 - accuracy: 0.4778 - val_loss: 1.3436 - val_accuracy: 0.4179\n",
      "Epoch 22/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1668 - accuracy: 0.4814 - val_loss: 1.2622 - val_accuracy: 0.4436\n",
      "Epoch 23/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1653 - accuracy: 0.4827 - val_loss: 1.2168 - val_accuracy: 0.4650\n",
      "Epoch 24/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1594 - accuracy: 0.4846 - val_loss: 1.2816 - val_accuracy: 0.4421\n",
      "Epoch 25/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1588 - accuracy: 0.4916 - val_loss: 1.3534 - val_accuracy: 0.4336\n",
      "Epoch 26/100\n",
      "175/175 [==============================] - 108s 614ms/step - loss: 1.1518 - accuracy: 0.4914 - val_loss: 1.2744 - val_accuracy: 0.4421\n",
      "Epoch 27/100\n",
      "175/175 [==============================] - 109s 620ms/step - loss: 1.1624 - accuracy: 0.4773 - val_loss: 1.2823 - val_accuracy: 0.4293\n",
      "Epoch 28/100\n",
      "175/175 [==============================] - 116s 660ms/step - loss: 1.1537 - accuracy: 0.4893 - val_loss: 1.3886 - val_accuracy: 0.4093\n",
      "Epoch 29/100\n",
      "175/175 [==============================] - 109s 622ms/step - loss: 1.1537 - accuracy: 0.4909 - val_loss: 1.2782 - val_accuracy: 0.4379\n",
      "Epoch 30/100\n",
      "175/175 [==============================] - 109s 623ms/step - loss: 1.1473 - accuracy: 0.4937 - val_loss: 1.4700 - val_accuracy: 0.3879\n",
      "Epoch 31/100\n",
      "175/175 [==============================] - 111s 631ms/step - loss: 1.1578 - accuracy: 0.4916 - val_loss: 1.2621 - val_accuracy: 0.4457\n",
      "Epoch 32/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1462 - accuracy: 0.4905 - val_loss: 1.2651 - val_accuracy: 0.4429\n",
      "Epoch 33/100\n",
      "175/175 [==============================] - 109s 621ms/step - loss: 1.1512 - accuracy: 0.4889 - val_loss: 1.2920 - val_accuracy: 0.4314\n",
      "Epoch 34/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1480 - accuracy: 0.4879 - val_loss: 1.2832 - val_accuracy: 0.4414\n",
      "Epoch 35/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1452 - accuracy: 0.4987 - val_loss: 1.3004 - val_accuracy: 0.4364\n",
      "Epoch 36/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1440 - accuracy: 0.4937 - val_loss: 1.2782 - val_accuracy: 0.4400\n",
      "Epoch 37/100\n",
      "175/175 [==============================] - 108s 619ms/step - loss: 1.1497 - accuracy: 0.4934 - val_loss: 1.3124 - val_accuracy: 0.4236\n",
      "Epoch 38/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1480 - accuracy: 0.4886 - val_loss: 1.2971 - val_accuracy: 0.4429\n",
      "Epoch 39/100\n",
      "175/175 [==============================] - 112s 637ms/step - loss: 1.1451 - accuracy: 0.4925 - val_loss: 1.2545 - val_accuracy: 0.4471\n",
      "Epoch 40/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1481 - accuracy: 0.4884 - val_loss: 1.2562 - val_accuracy: 0.4471\n",
      "Epoch 41/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 1.1406 - accuracy: 0.4943 - val_loss: 1.2795 - val_accuracy: 0.4400\n",
      "Epoch 42/100\n",
      "175/175 [==============================] - 108s 617ms/step - loss: 1.1406 - accuracy: 0.4996 - val_loss: 1.2851 - val_accuracy: 0.4471\n",
      "Epoch 43/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1342 - accuracy: 0.4989 - val_loss: 1.2494 - val_accuracy: 0.4514\n",
      "Epoch 44/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1434 - accuracy: 0.4955 - val_loss: 1.2736 - val_accuracy: 0.4407\n",
      "Epoch 45/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 1.1382 - accuracy: 0.4948 - val_loss: 1.3144 - val_accuracy: 0.4314\n",
      "Epoch 46/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 1.1427 - accuracy: 0.4987 - val_loss: 1.2737 - val_accuracy: 0.4393\n",
      "Epoch 47/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1367 - accuracy: 0.5013 - val_loss: 1.2486 - val_accuracy: 0.4557\n",
      "Epoch 48/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1393 - accuracy: 0.4950 - val_loss: 1.2454 - val_accuracy: 0.4543\n",
      "Epoch 49/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1441 - accuracy: 0.4986 - val_loss: 1.2406 - val_accuracy: 0.4486\n",
      "Epoch 50/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 1.1367 - accuracy: 0.5005 - val_loss: 1.2879 - val_accuracy: 0.4443\n",
      "Epoch 51/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1398 - accuracy: 0.4986 - val_loss: 1.3027 - val_accuracy: 0.4336\n",
      "Epoch 52/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 1.1376 - accuracy: 0.4937 - val_loss: 1.2580 - val_accuracy: 0.4507\n",
      "Epoch 53/100\n",
      "175/175 [==============================] - 108s 617ms/step - loss: 1.1380 - accuracy: 0.4995 - val_loss: 1.2201 - val_accuracy: 0.4636\n",
      "Epoch 54/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1314 - accuracy: 0.5088 - val_loss: 1.2464 - val_accuracy: 0.4579\n",
      "Epoch 55/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1346 - accuracy: 0.5027 - val_loss: 1.2476 - val_accuracy: 0.4607\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1301 - accuracy: 0.4982 - val_loss: 1.2759 - val_accuracy: 0.4414\n",
      "Epoch 57/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1310 - accuracy: 0.5020 - val_loss: 1.2697 - val_accuracy: 0.4457\n",
      "Epoch 58/100\n",
      "175/175 [==============================] - 110s 626ms/step - loss: 1.1290 - accuracy: 0.5023 - val_loss: 1.2558 - val_accuracy: 0.4443\n",
      "Epoch 59/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1327 - accuracy: 0.4980 - val_loss: 1.2592 - val_accuracy: 0.4464\n",
      "Epoch 60/100\n",
      "175/175 [==============================] - 107s 611ms/step - loss: 1.1307 - accuracy: 0.5082 - val_loss: 1.2385 - val_accuracy: 0.4579\n",
      "Epoch 61/100\n",
      "175/175 [==============================] - 113s 648ms/step - loss: 1.1313 - accuracy: 0.5077 - val_loss: 1.2428 - val_accuracy: 0.4586\n",
      "Epoch 62/100\n",
      "175/175 [==============================] - 109s 621ms/step - loss: 1.1254 - accuracy: 0.5027 - val_loss: 1.2164 - val_accuracy: 0.4729\n",
      "Epoch 63/100\n",
      "175/175 [==============================] - 108s 618ms/step - loss: 1.1311 - accuracy: 0.5002 - val_loss: 1.2353 - val_accuracy: 0.4607\n",
      "Epoch 64/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1226 - accuracy: 0.5127 - val_loss: 1.2445 - val_accuracy: 0.4621\n",
      "Epoch 65/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1306 - accuracy: 0.5038 - val_loss: 1.2578 - val_accuracy: 0.4529\n",
      "Epoch 66/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1243 - accuracy: 0.5073 - val_loss: 1.2542 - val_accuracy: 0.4543\n",
      "Epoch 67/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1220 - accuracy: 0.5096 - val_loss: 1.2509 - val_accuracy: 0.4521\n",
      "Epoch 68/100\n",
      "175/175 [==============================] - 108s 614ms/step - loss: 1.1296 - accuracy: 0.5052 - val_loss: 1.2637 - val_accuracy: 0.4486\n",
      "Epoch 69/100\n",
      "175/175 [==============================] - 107s 612ms/step - loss: 1.1201 - accuracy: 0.5071 - val_loss: 1.2532 - val_accuracy: 0.4543\n",
      "Epoch 70/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1135 - accuracy: 0.5105 - val_loss: 1.2249 - val_accuracy: 0.4671\n",
      "Epoch 71/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1296 - accuracy: 0.5020 - val_loss: 1.2469 - val_accuracy: 0.4514\n",
      "Epoch 72/100\n",
      "175/175 [==============================] - 112s 638ms/step - loss: 1.1287 - accuracy: 0.4979 - val_loss: 1.2435 - val_accuracy: 0.4593\n",
      "Epoch 73/100\n",
      "175/175 [==============================] - 107s 611ms/step - loss: 1.1241 - accuracy: 0.5036 - val_loss: 1.2344 - val_accuracy: 0.4550\n",
      "Epoch 74/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1305 - accuracy: 0.5025 - val_loss: 1.2346 - val_accuracy: 0.4543\n",
      "Epoch 75/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1265 - accuracy: 0.5009 - val_loss: 1.2388 - val_accuracy: 0.4579\n",
      "Epoch 76/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1192 - accuracy: 0.5105 - val_loss: 1.2378 - val_accuracy: 0.4514\n",
      "Epoch 77/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1206 - accuracy: 0.5075 - val_loss: 1.2655 - val_accuracy: 0.4393\n",
      "Epoch 78/100\n",
      "175/175 [==============================] - 108s 617ms/step - loss: 1.1159 - accuracy: 0.5048 - val_loss: 1.2691 - val_accuracy: 0.4414\n",
      "Epoch 79/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1154 - accuracy: 0.5007 - val_loss: 1.2394 - val_accuracy: 0.4529\n",
      "Epoch 80/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1255 - accuracy: 0.5041 - val_loss: 1.2448 - val_accuracy: 0.4586\n",
      "Epoch 81/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1215 - accuracy: 0.5064 - val_loss: 1.2384 - val_accuracy: 0.4550\n",
      "Epoch 82/100\n",
      "175/175 [==============================] - 108s 614ms/step - loss: 1.1238 - accuracy: 0.5025 - val_loss: 1.2702 - val_accuracy: 0.4493\n",
      "Epoch 83/100\n",
      "175/175 [==============================] - 112s 639ms/step - loss: 1.1197 - accuracy: 0.5021 - val_loss: 1.2331 - val_accuracy: 0.4586\n",
      "Epoch 84/100\n",
      "175/175 [==============================] - 108s 617ms/step - loss: 1.1226 - accuracy: 0.5082 - val_loss: 1.2465 - val_accuracy: 0.4586\n",
      "Epoch 85/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1229 - accuracy: 0.5095 - val_loss: 1.2582 - val_accuracy: 0.4471\n",
      "Epoch 86/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1090 - accuracy: 0.5123 - val_loss: 1.2404 - val_accuracy: 0.4543\n",
      "Epoch 87/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1136 - accuracy: 0.5089 - val_loss: 1.2515 - val_accuracy: 0.4579\n",
      "Epoch 88/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1255 - accuracy: 0.4986 - val_loss: 1.2739 - val_accuracy: 0.4450\n",
      "Epoch 89/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1160 - accuracy: 0.5107 - val_loss: 1.2688 - val_accuracy: 0.4486\n",
      "Epoch 90/100\n",
      "175/175 [==============================] - 110s 627ms/step - loss: 1.1205 - accuracy: 0.5114 - val_loss: 1.2127 - val_accuracy: 0.4657\n",
      "Epoch 91/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1244 - accuracy: 0.5063 - val_loss: 1.2397 - val_accuracy: 0.4579\n",
      "Epoch 92/100\n",
      "175/175 [==============================] - 108s 615ms/step - loss: 1.1127 - accuracy: 0.5141 - val_loss: 1.2577 - val_accuracy: 0.4514\n",
      "Epoch 93/100\n",
      "175/175 [==============================] - 107s 612ms/step - loss: 1.1113 - accuracy: 0.5038 - val_loss: 1.2380 - val_accuracy: 0.4550\n",
      "Epoch 94/100\n",
      "175/175 [==============================] - 112s 638ms/step - loss: 1.1138 - accuracy: 0.5127 - val_loss: 1.2666 - val_accuracy: 0.4550\n",
      "Epoch 95/100\n",
      "175/175 [==============================] - 111s 633ms/step - loss: 1.1225 - accuracy: 0.5059 - val_loss: 1.2623 - val_accuracy: 0.4471\n",
      "Epoch 96/100\n",
      "175/175 [==============================] - 109s 620ms/step - loss: 1.1216 - accuracy: 0.5034 - val_loss: 1.2439 - val_accuracy: 0.4593\n",
      "Epoch 97/100\n",
      "175/175 [==============================] - 108s 616ms/step - loss: 1.1208 - accuracy: 0.5077 - val_loss: 1.2425 - val_accuracy: 0.4493\n",
      "Epoch 98/100\n",
      "175/175 [==============================] - 107s 613ms/step - loss: 1.1156 - accuracy: 0.5123 - val_loss: 1.2288 - val_accuracy: 0.4600\n",
      "Epoch 99/100\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 1.1083 - accuracy: 0.5171 - val_loss: 1.2364 - val_accuracy: 0.4600\n",
      "Epoch 100/100\n",
      "175/175 [==============================] - 107s 612ms/step - loss: 1.1173 - accuracy: 0.5100 - val_loss: 1.2518 - val_accuracy: 0.4550\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "history = model.fit(imgs_train, \n",
    "                    y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(imgs_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8c7b3a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 243,655\n",
      "Trainable params: 243,207\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5),\n",
    "                 padding='valid',\n",
    "                 input_shape=(128, 128, 3),\n",
    "                 activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(units=490, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 72/200 [=========>....................] - ETA: 1:14 - loss: 1.7506 - accuracy: 0.3147"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "history = model.fit(imgs_train, \n",
    "                    y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(imgs_test, y_test))\n",
    "\n",
    "#I made it so the learning rate does not decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59f7a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: Save the weights if good, repeat process to upload different set of 8000 images, run again\n",
    "# Also need to attempt segmentation side - use pretrained UNet\n",
    "\n",
    "#This website seems like it will be very helpful: https://segmentation-models.readthedocs.io/en/latest/tutorial.html\n",
    "# My guess is that our y- values will have to change to the coordinates that indicate where the hemorrhage is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936a6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
